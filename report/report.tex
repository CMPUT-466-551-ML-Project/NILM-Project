%
% latex-sample.tex
%
% This LaTeX source file provides a template for a typical research paper.
%

%
% Use the standard article template.
%
\documentclass{article}

\usepackage{geometry}
\geometry{letterpaper}

\usepackage{cite}
\usepackage{doc}
\usepackage{url}
\usepackage{graphicx}
\usepackage{aaai}
\usepackage{amsmath}
\usepackage{epstopdf}
\usepackage{hyperref}

\title{Energy Disaggregation}
\author{Henry Agsten, Jacob Denson, Jesse Huard, Isabel McCarten, Morgan Redshaw}
\date{}

\begin{document}

\maketitle

\begin{abstract}
Whatever we exactly did. Something about how, for Internet of Things, device on/off is more readily available
Would be very useful if could train off it combined with the aggregated data, rather than also using the disaggregated data or taking an unsupervised approach.
\end{abstract}

NOTE: Needs to be cleaned up now
NOTE: sub-metering is the word we want for measuring disaggregated energy signals
%TODO: Do we assume that are either ON or OFF, or that they can have multiple levels?
	%NOTE: another paper assumed that 'all appliances that have more than two states (e.g., on and off) will produce events that can be explained by two-state appliances'
%TODO: Outline where we got the data from

\section{Introduction}

Energy disaggregation, or non-intrusive load-monitoring (NILM), is the problem of estimating a household's individual appliance energy consumption given measurements from a single sensor which records the aggregate power consumption of the household over time.
While measuring the power draw of each device in a home directly yields more accurate results than machine learned techniques, it usually involves either expensive instrumentation of the devices we wish to measure the energy consumption of or an intrusion into the home in order to set up power monitoring hardware.
Both situations are undesirable for the homeowner, so instead NILM makes use of already existing infrastructure combined with machine learned techniques, in order to provide an estimate of device energy consumption.

Having access to disaggregated energy consumption is useful to homeowners, as studies have shown that when presented with this information, they are more motivated to reduce their energy consumption \cite{Darby}.
Additionally, this information can be used to identify devices in a home which have become faulty and are in need of repair.
When a device breaks, changes in its energy consumption patterns can be detected by an automated system, allowing the homeowner to be notified that the device needs servicing.

Most existing machine learning methodologies for NILM are trained using data from households which have been instrumented to record the power consumption of each device separately, in addition to the aggregate household power usage \cite{Kelly}\cite{Cicchetti}.
However, as noted above, this instrumentation is expensive and makes it difficult to gather new data, with most existing datasets being limited to recording from only a small number of homes \cite{Redd}\cite{Kelly2}.
This lack of data from many homes has the effect of making it difficult to see how well current NILM algorithms generalize to unseen homes, and can be problematic with algorithms which require large amounts of data, such as deep neural network architectures \cite{Kelly}.

The authors of this paper believe it is valuable to explore machine learning techniques which use only the binary on-off indicators of household devices during training, as opposed to the raw power consumption of each device.
With the rise of the ``Internet of Things'', it seems reasonable that in the near future, network-enabled home appliances will be able to report their periods of activity to a remote data analytics platform \cite{Gubbi}.
Once collected, these binary indicators can be used along with the aggregate power consumption data to find an approximation to the power draw of each individual device in the household.
These binary indicators forgo the need for expensive instrumentation in each device to monitor power usage, meaning that training data can be continuously collected by an automated system operating at a large scale.

In this paper, we investigate several different pre-processing algorithms for approximating single device power usage given a household's aggregate power usage and binary on-off indicators for each device in the home.
To evaluate the effect of our pre-processing compared to state-of-the-art NILM algorithms which use single device power consumption, we use a previously-identified neural network architecture based on denoising auto-encoders \cite{Kelly}.
For each device network, we will train separately on the raw device power usage and the approximate power usage obtained by each pre-processing algorithm.
We will then compare the output of each device network to a hold-out set, in order determine the performance impact of our pre-processing algorithms on the NILM task.

\section{Related Work}

%NOTE: Should focus on research relevant to ours. Don't know how much there is.
%TODO: Should also outline one or two unsupervised approaches.
As far as we know, no studies of NILM using only information about the activity of each device per timestep, exist.
%TODO: Cite all of these
There have been supervised approaches using the disaggregated energy\cite{Kelly} or energy signatures \cite{Parson} for each device.
Some unsupervised approaches also exist that only use the aggregated energy of the overall house \cite{Kolter}.
%TODO: Mention something about related approaches or similar ideas?

%\subsection{Independent Component Analysis}

%TODO: Soundwaves is the wrong word
%To use ICA, we would need to assume that the signature for each device is statistically independent, which is unfortunately not true.
%TODO: Find citation for this
%As well, ICA performs best when there are multiple different 'sound waves', but with NILM there would only be the power being used by the house for each timestep.
%Thus, we believe that applying independent component analysis will not achieve significantly better results to existing methods.

%TODO: Should these be the approach name, or something else?

\subsection{Approaches using no information about single device consumption}
Unsupervised proceedings to disaggregate consumption data rely mainly on Hidden Markov Models. 
Kolter \cite{Kolter} uses one Hidden Markov Model per device to describe its consumption and figure out at what time 
it was active. He finds periods of activity, clusters similar ones and builds a Hidden Markov Model per device. 
Unfortunately the process to find these periods is not described in detail but seems to look for intervals when only 
one device is active, what we want to enhance. He claims to reach precision values of over 90\% for some devices but since the recall values are not 
given it is hard to judge these results. 
In contrast to this completely unsupervised approach, Parson starts with knowledge about the general device type and 
gives a generic model for each device, which is fitted to the actual device. His biggest benefits are identifying the 
devices without labeling them manually, since his generic models are labeled once and that he compares the house's device with 
the set of models, so it is not necessary to know how many device are in the house. For devices with clearly distinguished patterns 
(e.g. fridges) Parson reaches F-scores up to 85\% while achieving results under 20\% for unstable devices (e.g. Microwaves).
Even though his allocation of generic models and minute-wise measurements did not seem useful for us, his work led 
us to the REDD-dataset which he used
and to the idea of looking for timesteps when only one device changes its activity status.

\subsection{Approaches using information about single device consumption}

%TODO: Citations for this
The most common supervised approaches use Hidden Markov Models as well as neural networks to estimate the power consumption 
for each device.

Well known is Parson's \cite{Parson} usage of one difference Hidden Markov Model (dHMM) per device to describe its 
consumption and figure out at what time it was active.
%TODO: Make sure is correct, and possibly cite this
A dHMM extends traditional Hidden-Markov-Models by additional hidden variables for the difference from the previous 
to current state. While this approach does not require the disaggregated energy signature per device, it does require 
prior knowledge in the form of ???

Latest progress was made by applying deep neural nets, where Kelly and Knottenbelt \cite{Kelly} used recurrent neural 
nets with four hidden layers and achieved positive results for stable-behaving devices, but lacked accuracy for multi-stated 
ones, leading to a F-score of 51\%. They also considered denoising autoencoders training one neural net per appliance. 
The neural net takes the power consumption within a sliding window as input and separates the devices consumption from 
the remaining power. Determining the window size by the usual activity time of the device they achieve an F-score of 70\%. 
Both of their approaches use in the training phase the separated energy consumption for every device, ignoring possible inherent 
relationships between different devices. Furthermore they identify that often signal reconstruction is not integral to applications.
Therefore, they take their task to be identification of a begin time, end time, and overall energy usage of a specific device, 
during the first cycle it is used.
%They attempt to solve the problem via an amalgamation of Constitutional, Feed forward, and recurrent neural nets, combined with 
%a denoising error\footnote{Viewing other data as `noise' may also cut out the holistic approach to the problem, removing the 
%problem of global consistency.} and training on each device individually\footnote{This may ignore inherent relationships between 
%different devices (though perhaps the neural networks account for this).
%Perhaps a way to `double check' nets are correct may provide a more effective, holistic approach.}.
%Due to the extensive data set one needs to train deep nets, the pair generates synthetic data by combining data with `noise' data\footnote{The data they generate is naive, and we will likely see performance increases from a more realistic generation of data, or through pre-training on large amounts of unlabelled data, then a less extensive training on real data.}.
Weiss \cite{Weiss} presumes the power consumption as a sequence of piecewise constant consumption levels those differences 
describe the typical consumption pattern of a distinct device. They identify devices by checking for characteristic 
differences 
between consumption changes and look for the most similar device pattern via neareast neighbor calculation. Since they get remarkable 
F-scores of 80\% and higher for some devices although the strong assumption we also have a look on signal for which this assumption holds.


%I did not understand how data was selected for training, but I do no it is normalized to have mean zero -- which may or may not reduce the ability to consistently identify features.
​
%Questions about the paper:
%
%\begin{enumerate}
%	\item Using Convolutional Neural networks (Time Invariant).
%	\item Ignoring all but first activation.
%	\item Why does the algorithm ignore all but the first activation.
%	\item Local to Global.
%	\item NILMTK will be useful!
%	\item Periodicity.
%\end{enumerate}
​
%One neural network is trained per target appliance, based on real data and synthetically generated data.

%**Another interesting aspect of the paper was how they used Denoising Autoencoders.
​
\subsubsection{Baranski's Algorithm}

\subsubsection{Neural Networks}
​
Another approach that has been used in energy disaggregation is neural networks. For example, \cite{Ruzzelli} used simple, three-layer neural networks on the problem but used more information than we had about the appliances as input, including information about the current and voltage. We did not pursue this technique since, with just the power consumption as input, the main way to distinguish appliances is via patterns over time and a simple neural network has no way to do this. Another type of neural network which is an obvious choice for this problem and which we initially considered using is deep, recurrent networks. This method had been tried  before by \cite{Kelly} which experimented with using recurrent neural networks for energy disaggregation. Its net used a bidirectional long short term memory architecture \cite{Kelly}, which involves a memory unit with input, output, and feedback gates and is intended to overcome the problem of vanishing gradients over long sequences of inputs. Although the recurrent neural network produced reasonable results with recall and precision scores of 0.85 and 0.36, \cite{Kelly} experimented with several types of neural networks, and this one did not produce the best results. In particular it performed poorly on appliances with more than the two, on/off states. The neural network we used, which falls into a category called denoising autoencoders, was based on another of the nets \cite{Kelly} tested which outperformed the recurrent neural network.


\section{Our Stuff}

%TODO: This one could be useful
%Known as nonintrusive load monitoring (NILM) various researchers have investigated this problem.
%Weiss (Source3?) presume the power consumption as a sequence of piecewise constant consumption levels whose differences describe the typical consumption pattern of a distinct device.
%Since they get remarkable F-scores of 80\% and higher for some devices we also had a look for signal where this assumption holds.

Unlike many of the other methods, we are assuming that we do not have the disaggregated power signature for each device during the learning stage.
Instead, we assume we have accurate information about when each device is active, due to the trend of the "Internet of Things", where many devices are connected to the internet, and could thus provide information about when they are active.
%TODO: Get paper for this?


\subsection{Dataset}
As a basis to evaluate our approach we use the Reference Energy Disaggregation Data Set (REDD) \cite{Redd}, a collection of energy consumption 
from six houses where the mains, single devices and circuits were measured separately over two weeks. Even though the data set contains high-frequent 
measurings we use the ones with frequencies between $1$ and $3 Hz$, to stay comparable to former works with similar frequencies. Since not all 
device exist in every house we focused on the most common ones: dishwasher, washer-dryer-combinations (both in all houses), refridgerator (in 5 
out of 6 houses) as well as microwave and stove (in all but two houses). Since the sum of all single devices and circuits does not sum up to the 
measured overall consumption, because small devices like consumer electronics were not traced, we compare two different approaches one with noise 
and one without. For the unnoised method we sum up only the consumption of the focused devices and take their sum as the aggregated energy consumption. 
We check these results against the ones where we subtract the devices which are not of interest for us from the measured overall consumption, which 
gives us a bigger than natural noise.\\
Our goal is to work only with the information if a device is inactive or active, whereby active means that it is actually on and not only in a
standby mode. To generate the  on/off-indicators we check the dataset against a threshold $\delta$, assigning the device an indicator of $1$ if its 
consumption in the relevent time step exceeds the threshhold and considering the device as inactive otherwise, assigning $0$. Using the threshold 
eliminates the uninteresting phases of permant standby uses, as they are common especially in refridgerators.

\subsubsection{Denoising Autoencoders}

The neural network we used, as mentioned above, belongs to a type called denoising autoencoders and is based on the one from \cite{Kelly}. An autoencoder is a type of neural network with input and output layers the same size and a smaller hidden layer between them where the input and the target are the same. As a result the output of the hidden layer is effectively a compressed encoding of the original data. A denoising autoencoder is one where the input is a corrupted version of the signal, and the output is checked against the uncorrupted version. They are typically used to remove grain and noise from photos and sound recordings. 
Denoising autoencoders can be applied to energy disaggregation by using a separate neural network for every appliance and using the power consumption over an extended window of time as both the input and the output. The input or corrupted signal is a vector of size T giving the aggregated power consumption over a time window of length T, and the target or uncorrupted signal is another vector giving the power consumption of one appliance over the same window, so the other appliances in the aggregated power usage are treated as noise \cite{Kelly}. Using the power over a time window as input is why it is able to recognise patterns in power consumption over time without being a recurrent neural net.

Having discussed denoising autoencoders in general, we move on to the details of the neural networks we used. Each appliance had its own network as mentioned above, and each of them had six layers. The size of the input window was customized to how long each appliance was turned on, on average, so the input layer varied in size between the networks. After the input window was a convolutional layer with eight filters of size four. The third and fifth layers were both dense layers the same size as the output of the first convolutional layer with a smaller dense layer of 128 nodes between them. These three layers are what make up the actual denoising autoencoder. The final layer was a second convolutional one with one filter of size four \cite{Kelly}. The final layer treats its input as eight dimensional rather than one, and so reverses the increase in the size of the layers caused by the eight filters of the first convolutional layer, and compresses the output back down to the correct size to be compared to the target.

We also standardized the input before running the neural network. Every input window had its mean subtracted. This does lose some information, but experiments, both our own and \cite{Kelly}'s, suggest that neural networks generalize better when each sequence is centered separately and that the gains from this outweigh loses from throwing away the information about the average value. Also every sample was divided by the standard deviation of a random sample of the input, and the target output was divided by the maximum power demand of the device to put it in the range of 0 to 1 \cite{Kelly}. 

The paper comparing neural networks shows the denoising autoencoder as having a recall score of 94 and a precision score of 56 \cite{Kelly}. Before we ran our experiment based on just the on/off binary information, we ran our denoising autoencoder with the actual disaggregated power consumption as the target output on the REDD dataset attempting to get numbers close to these ones to test that our neural network was working correctly.


\section{Preprocessing}
​
Robust evaluation metrics are essential to applying supervised learning techniques. Unfortunately, obtaining reasonable metrics is near impossible without actual power outputs of individual devices. Nonetheless, we are still interested in applying supervised approaches, which have a strong history of success in energy disaggregation. Our solution estimates individual outputs on the training data, as a preprocessing step to train a more powerful prediction algorithm. We emphasize that as a general prediction method, the preprocessing algorithms we describe are not viable, since after the training phase we have no access to device on/off indicators, which are key in obtaining power output.
​
Inferring general power outputs is an underdetermined problem. Good results can therefore only be obtained by making strict assumptions about the statistical model producing the data. Here, we apply two separate models: The simplest assumes that good estimates are obtained from a constant power estimate, the second that each device is represented by a restricted family of markov processes.
​
In the sequel, the following notation will be convenient. We shall let $N$ denote the number of devices we are observing, and $T$ the number of time epochs. The random variable $X_i^t$ models the output of the device $i$ at the time $t$, and $Y^t = \sum X_i^t$ denotes the total power output. We observe the indicators $I_i^t = \mathbf{I}(X_i^t > 0)$ and $Y^t$ over the range of $i$ and $t$, and must predict the $X_i^t$ to the best of our ability.
​
\subsection{A Constant Power Assumption}
​
In our first model, we assume that the output of devices are mutually independant, and that the outputs of a specific device are i.i.d with respect to time, when that device is switched on. The mathematics tells us that there are numbers $P_1, \dots, P_n \in \mathbf{R}^+$ for which $X_i^t = P_i + \varepsilon_i$, where $\mathbf{E}(\varepsilon_i) = 0$. Assuming error variances are small, we conclude that treating the power output of a device as constant when it is switched on is accurate, and our problem reduces to finding the values $P_i$. After the $P_i$ are predicted, output estimations are calculated
%
\[ \hat{X_i^t} = I_i^t P_i \]
%
Finding $P_i$ is feasable, once an optimization metric is obtained.
​
The simplest way to choose the $P_i$ is to minimize the $L_2$ error of our estimated total
%
\[ \hat{Y}^t = \sum_{i = 1}^n \hat{X_i^t} = \sum_{i = 1}^n I_i^t P_i \]
%
with respect to the known total $Y^t$. This leads to thehis can be easily found by the optimization
%
\[ \min_{P_1, \dots, P_n \in \mathbf{R}^+} \sum_{t = 1}^T \left( Y^t - \sum_{i = 1}^n I_i^t P_i \right)^2 \]
%
In our implementation, we use Scipy's {\it optimize()} method to determine the $P_i$, which uses a sequential least-squares algorithm.
​
\subsection{Estimating Difference Markov Processes}
​
An alternate model assumes the underlying processes generating appliance power outputs are mutually independant markov models. As an extension of the previous model, the power outputs of devices are constant when the underlying chain remains in a single state. This should suffice for most practical applications, since most appliances change their power load only when running in a different `mode' (an oven cooking at different temperatures, a computer under different stress levels, etc.).
​
Mathematically speaking, the outputs $X_i^t$ are drawn from some hidden markov model with states $S^i_0, S^i_1, \dots, S^i_{K_i}$, where $S_0$ is the `off' state ($X_i^t = 0$) and that, given that the markov model is in a state $S^i_k$ at some time $t$, then $X_i^t \sim \mu_i^k + \varepsilon_i^k$, where $\mathbf{E}(\varepsilon_i) = 0$, and $\mu_i^k \in \mathbf{R}^+$ are fixed. Once we have estimated such a model, we may estimate the $X_i^t$ by a best fit method -- calculating the state transition that results in the best fit. We don't ever need to calculate transition probabilities, since our knowledge of the indicator functions effectively removes most of the randomness from the calculation.
​
Hidden markov chains are still difficult to estimate, so restriction of the markov model's structure is necessary. In words, we restrict the model such that it is unable to transition from any on state to any on state directly -- it must pass through the off state in order to transition to these states. A general diagram for such a markov chain is displayed below. It is hard enough to estimate the means, so we assume that the states of the markov diagram have been given by divine insight -- this is a classic problem; too many states will overfit the data, too few will underfit.
%
% PLACEHOLDER IMAGE
\begin{center}
\includegraphics[scale = 0.5]{process-probabilities}
\end{center}
%
To further reduce the dimensionality, we follow Kolter's approach to the Markov model problem by considering difference Markov models\footnote{described in [1], see the section on additive markov models}. Rather than working with the data $Y^t$, we choose only to use values $\Delta Y^t := Y^t - Y^{t-1}$ at timepoints $t$ where the $i$'th device switches on ($\mathbf{I}(X_i^{t-1} > 0) = 0$ and $\mathbf{I}(X_i^t > 0) = 1$). Hopefully, this difference describes the average power over the entire interval where the device is switched on. Even if it doesn't, we should have enough data to filter out errors. At these time points, it is very likely that our device will be the only device to change state, for we are effectively viewing a discrete embedding into a continuous time markov chain, and it is common knowledge that in such a chain that, given our embedding is sufficiently fine, two state changes will very rarely occur at once. We then attempt to optimize our choice of $\mu_i$ redefining $X_i^{t + k} = \Delta Y^t$, where $X_i^{t + l} > 0$ for $l \in \{0, 1, \dots, k\}$.
​
Now we shall describe the optimization for a specific device $i$. Suppose that, the device enters a series of intervals of lengths $l_1, \dots, l_M$, taking difference values $\Delta Y^{t_1}, \dots, \Delta Y^{t_M}$ in each interval. We proceed to determine the values $\mu_1, \dots, \mu_K$ by minimizing the best fit over the data. Minimization over the $L_1$ norm will be used, since we may take advantage of its discrete qualities
%
\begin{equation} \min_{\mu_1, \dots, \mu_K} \sum_{i = 1}^M l_i \min_{k \in \{ 1, \dots, K \}}|\Delta Y^{t_i} - \mu_k| \end{equation}
%
There is a geometric interpretations of this minimization. Viewing the $\Delta Y^{t_i}$ as points, each with a `weight' $l_i$, we are attempting to choose the best centers of mass $\mu_1, \dots \mu_n$ which distribute themselves evenly between the points $\Delta Y^{t_i}$.
​
If we vary just one of the means $\mu_i$ in (1), we obtain a piecewise linear function. It follows that the minima $\mu_i$ may always be chosen to lie at the edge points of the function, which are the values $\Delta Y^{t_i}$. This leads to a discrete problem (which is not true for other $L_p$ norms), which we may solve through dynamic programming. First, we order the $\Delta Y^{t_i}$. Suppose $\mu_1 < \mu_2 < \dots < \mu_K$ is the optimal solution to our problem. If we remove $\mu_K$, then $\mu_1 < \dots < \mu_{K-1}$ is the optimal solution to the subproblem of distributing $K-1$ means among the subset of points who's closest mean is not $\mu_K$ (for otherwise we can move these means to improve our current solution). We therefore can work backwards dynamically to obtain a solution. From this optimal substructure, we obtain the simple recurrence: If we let $L(m,k)$ be the optimum cost of putting $k$ of the $\mu_i$ in the range $\{ t_1, \dots, t_m \}$, then we may choose an interval $\{ t_p, \dots, t_m \}$ for which $\mu_k$ will be the closest estimate, and then we optimize over $\{ t_1, \dots, t_p \}$ with one less estimate. Our reccurence is
%
\begin{align*}
    L(m,k) = \min_{k \leq p < m} \bigg\{ L(p,k-1) + \min_{p < i \leq m} \sum_{j = p+1}^m l_j |Y^{t_j} - Y^{t_i}| \bigg\}
\end{align*}
%
\[ L(1,1) = 0 \]
%
By keeping track of the location of the means recursively, we can build up the optimal $\mu_i$.

\subsection{Evaluation}
To compare our methods with each other and with existing approaches, we focus on two questions.\\
1. How well did we identify what devices where active in each time step?\\
2. How well did we identify the single devices‘ consumption?\\
To address the first question we use the F1-Score, ensuring our results to be comparable to the works in the section \textit{Literature}. The 
advantages of the F1-Score to combine recall and precision avoids contortions, which would arise by considering only one of them. Assume we 
identify the refridgerator being active in all time steps we get a optimal recall value, but a low precision, whereas we get a optimal precision 
by identifying the refridgerator never as active.
\[ \textrm{Precision} = \frac{\textrm{Number of true positive elements}}{\textrm{Number of elements identified as positives}}  \]
\[ \textrm{Recall} = \frac{\textrm{Number of true positives}}{\textrm{Number of elements that are indeed positive}}  \]
\[ \textrm{F1-Score} = \frac{2 \cdot \textrm{Precision} \cdot \textrm{Recall}}{\textrm{Precision} + \textrm{Recall}}\]
For the second question we are interested in the error per timestep and to generate acuuracy-like value. Therefore we
compare the disaggregated energy consumptions per device with the actual device's consumption we have from the REDD
dataset. Following \cite{Redd} we can compute the accuracy depending on the summed absolute deviation in relation to 
the overall consumption:
\[\textrm{Accuracy}_{abs} = 1- \frac{\sum^{T}_{t=1}\sum^{N}_{n=1}|\hat{y}^{(n)}_t-y^{(n)}_t|}{2 \sum^{T}_{t=1}Y_t} .  \]
The error per timestep can be similarly described as the absolute squared error:
\[\textrm{ASE} = \frac{\sum^{T}_{t=1}\sum^{N}_{n=1}|\hat{y}^{(n)}_t-y^{(n)}_t|}{T \cdot n} .  \]
While the absolute error weights all differences regardless of their size the same, we also want information about the accuracy when 
weighting bigger deviations higher than smaller ones. We use the root squared error instead of the squared error 
to stay within the same unit. Therewith we calculate the root mean squared error as the error per timestep and similar a respective 
accuracy as the ratio with summed up overall consumption.
\[\textrm{RMSE} = \sqrt{\frac{\sum^{T}_{t=1}\sum^{N}_{n=1}(\hat{y}^{(n)}_t-y^{(n)}_t)^2}{T \cdot n}} .  \]
\[\textrm{Accuracy}_{rse} = 1- \frac{\sqrt{\sum^{T}_{t=1}\sum^{N}_{n=1}(\hat{y}^{(n)}_t-y^{(n)}_t)^2}}{2 \sum^{T}_{t=1}Y_t} .  \]




%TODO: Whatever evaluation function to see how well the neural network does after training.
%May even want to use two or more, to see if they work better in different circumstances

%Then, we will compare the results for the different trained denoising autoencoder neural nets, based on the data that we preprocessed.

%Will train and evaluate on the devices %TODO: write out devices


%TODO: Example?



%TODO: Example?

\subsection{Implementation}
Our NILM and pre-processing implementations were written in Python, and are publicly available in our \href{https://github.com/CMPUT-466-551-ML-Project/NILM-Project}{NILM-Project} repository.

After choosing which devices from each home we wanted to train our networks against, we removed the contribution of all other devices present in the home from each home's aggregated power time-series.
We chose this approach, instead of generating new aggregated data by taking the sum of the power signal of the chosen devices from each home, in order to preserve the noise present in the aggregated power time-series.
This noise is present even when no recorded device in the home is active, and therefore needed to be preserved so that our networks could account for it during training.

The original data we used had some periods of missing data, and not all devices were sampled at the same frequency.
To overcome this, we padded our time-series data to be fully aligned across all devices and the aggregate recording.
Any missing sample period of less than 600 seconds was padded with the most-recently recorded power value.
Any missing sample period of more than 600 seconds was thrown out.
We used this padded data for training and evaluation.

In order to recover the binary on-off indicators for each device from the power signal, we use a simple thesholding algorithm.
If the power signal is over the threshold, we say that the device is on, and if the power signal is below the threshold, we say that the device is off.
In our implementation, we used a base threshold of 25W across all devices, to account for noise present in the signal.

Our pre-processing algorithms use these recovered binary on-off indicators, along with the padded aggregated data of each home, in order to generate an approximation of the device power usage for use when training our networks.

We implemented our neural networks using the Keras library \cite{Keras}.
Keras is built on top of the Theano library \cite{Theano}\cite{Theano2}.
Our network weights were initialized randomly from a uniform distribution.
All experiments described in this paper were trained end-to-end from the random initialization.
The input size of each network was chosen as the average activation length of the device the network was trained against.
The input size was bounded to a maximum 1500 seconds, due to memory constraints on the machines the networks were trained on.

\section{Discussion}

\subsection{Future work and Extension}

Extension to Baranski's Algorithm?.

HMM depending on how well that goes

Another possible extension to this project would be to add more information to the input of the neural network, such as the time of day and day of the week of the input window since certain appliances are more likely to be activated at certain times. Another option would be to find a way to include the information of what the mean of the input window was while still standardizing each input window by subtracting its mean\cite{Kelly}, perhaps by standardizing the power consumption used as the input and then adding the mean as a single number at the end of the input. However, it is not easy to see where the best place to insert this information into the denoising autoencoder architecture would be. Some experimentation would likely be necessary to find an architecture that made effective use of the new information.

% Generate the bibliography.

\bibliography{biblio}
\bibliographystyle{aaai}

\end{document}
