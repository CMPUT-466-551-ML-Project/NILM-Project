%
% latex-sample.tex
%
% This LaTeX source file provides a template for a typical research paper.
%

%
% Use the standard article template.
%
\documentclass{article}

\usepackage{geometry}
\geometry{letterpaper}

\usepackage{cite}
\usepackage{doc}
\usepackage{url}
\usepackage{graphicx}
\usepackage{aaai}
\usepackage{amsmath}
\usepackage{epstopdf}
\usepackage{hyperref}

\title{Energy Disaggregation}
\author{Henry Agsten, Jacob Denson, Jesse Huard, Isabel McCarten, Morgan Redshaw}
\date{}

\begin{document}

\maketitle

\begin{abstract}
Whatever we exactly did. Something about how, for Internet of Things, device on/off is more readily available
Would be very useful if could train off it combined with the aggregated data, rather than also using the disaggregated data or taking an unsupervised approach.
\end{abstract}

NOTE: Needs to be cleaned up now
NOTE: sub-metering is the word we want for measuring disaggregated energy signals
%TODO: Do we assume that are either ON or OFF, or that they can have multiple levels?
	%NOTE: another paper assumed that 'all appliances that have more than two states (e.g., on and off) will produce events that can be explained by two-state appliances'
%TODO: Outline where we got the data from

\section{Introduction}

Energy disaggregation, or non-intrusive load-monitoring (NILM), is the problem of estimating a household's individual appliance energy consumption given measurements from a single sensor which records the aggregate power consumption of the household over time.
While measuring the power draw of each device in a home directly yields more accurate results than machine learned techniques, it usually involves either expensive instrumentation of the devices we wish to measure the energy consumption of or an intrusion into the home in order to set up power monitoring hardware.
Both situations are undesirable for the homeowner, so instead NILM makes use of already existing infrastructure combined with machine learned techniques, in order to provide an estimate of device energy consumption.

Having access to disaggregated energy consumption is useful to homeowners, as studies have shown that when presented with this information, they are more motivated to reduce their energy consumption \cite{Darby}.
Additionally, this information can be used to identify devices in a home which have become faulty and are in need of repair.
When a device breaks, changes in its energy consumption patterns can be detected by an automated system, allowing the homeowner to be notified that the device needs servicing.

Most existing machine learning methodologies for NILM are trained using data from households which have been instrumented to record the power consumption of each device separately, in addition to the aggregate household power usage \cite{Kelly}\cite{Cicchetti}.
However, as noted above, this instrumentation is expensive and makes it difficult to gather new data, with most existing datasets being limited to recording from only a small number of homes \cite{Redd}\cite{Kelly2}.
This lack of data from many homes has the effect of making it difficult to see how well current NILM algorithms generalize to unseen homes, and can be problematic with algorithms which require large amounts of data, such as deep neural network architectures \cite{Kelly}.

The authors of this paper believe it is valuable to explore machine learning techniques which use only the binary on-off indicators of household devices during training, as opposed to the raw power consumption of each device.
With the rise of the ``Internet of Things'', it seems reasonable that in the near future, network-enabled home appliances will be able to report their periods of activity to a remote data analytics platform \cite{Gubbi}.
Once collected, these binary indicators can be used along with the aggregate power consumption data to find an approximation to the power draw of each individual device in the household.
These binary indicators forgo the need for expensive instrumentation in each device to monitor power usage, meaning that training data can be continuously collected by an automated system operating at a large scale.

In this paper, we investigate several different pre-processing algorithms for approximating single device power usage given a household's aggregate power usage and binary on-off indicators for each device in the home.
To evaluate the effect of our pre-processing compared to state-of-the-art NILM algorithms which use single device power consumption, we use a previously-identified neural network architecture based on denoising auto-encoders \cite{Kelly}.
For each device network, we will train separately on the raw device power usage and the approximate power usage obtained by each pre-processing algorithm.
We will then compare the output of each device network to a hold-out set, in order determine the performance impact of our pre-processing algorithms on the NILM task.

\section{Related Work}

%NOTE: Should focus on research relevant to ours. Don't know how much there is.
%TODO: Should also outline one or two unsupervised approaches.
As far as we know, no studies of NILM using only information about the activity of each device per timestep, exist.
%TODO: Cite all of these
There have been supervised approaches using the disaggregated energy\cite{Kelly} or energy signatures \cite{Parson} for each device.
Some unsupervised approaches also exist that only use the aggregated energy of the overall house \cite{Kolter}.
%TODO: Mention something about related approaches or similar ideas?

%\subsection{Independent Component Analysis}

%TODO: Soundwaves is the wrong word
%To use ICA, we would need to assume that the signature for each device is statistically independent, which is unfortunately not true.
%TODO: Find citation for this
%As well, ICA performs best when there are multiple different 'sound waves', but with NILM there would only be the power being used by the house for each timestep.
%Thus, we believe that applying independent component analysis will not achieve significantly better results to existing methods.

%TODO: Should these be the approach name, or something else?

\subsection{Hidden Markov Models}
Hidden Markov Models are one of the main categories of methods used for energy dissagregation.
For example, \cite{Kolter} used one Hidden Markov Model per device to describe its consumption and figure out what time 
it was active at. Kolter's algorithm finds periods of activity, clusters similar ones and builds one hidden Markov model per device. 
Unfortunately the process to find these periods is not described in detail but seems to look for intervals when only 
one device is active. For some devices, \cite{} claims to reach precision values of over 90\%, but since the recall values are not 
given it is hard to judge these results. 

In contrast to this completely unsupervised approach, Parson starts with knowledge about the general device type and 
produces a generic model for each device, which is fitted to the actual device. The generic and fitted models are difference hidden Markov models which have a second observation sequence representing the difference in power consumption between two time steps. The algorithm's biggest benefits are that it identifys the 
devices without labeling them manually unlike most unsupervised methods in which the output dissagregated power consumption for some device has to be manually matched with a real-life device, and that it does not require the assumption that the number of devices in the house is known. For devices with clearly distinguished patterns 
(e.g. fridges) Parson reaches F-scores up to 85\% while achieving results under 20\% for unstable devices (e.g. Microwaves).
Even though his allocation of generic models and minute-wise measurements did not seem useful for us, his work led 
us to the REDD-dataset which he used
and to the idea of looking for timesteps when only one device changes its activity status.


%TODO: Citations for this

%Weiss \cite{Weiss} presumes the power consumption as a sequence of piecewise constant consumption levels those differences 
%describe the typical consumption pattern of a distinct device. They identify devices by checking for characteristic 
%differences 
%between consumption changes and look for the most similar device pattern via neareast neighbor calculation. Since they get remarkable 
%F-scores of 80\% and higher for some devices although the strong assumption we also have a look on signal for which this assumption holds.

%\subsubsection{Baranski's Algorithm}

\subsubsection{Neural Networks}
​
Another approach that has been used in energy disaggregation is neural networks. For example, \cite{Ruzzelli} used simple, three-layer neural networks on the problem but used more information than we had about the appliances as input, including information about the current and voltage. We did not pursue this technique since, with just the power consumption as input, the main way to distinguish appliances is via patterns over time and a simple neural network has no way to do this. Another type of neural network which is an obvious choice for this problem and which we initially considered using is deep, recurrent networks. This method had been tried  before by \cite{Kelly} which experimented with using recurrent neural networks for energy disaggregation. Its net used a bidirectional long short term memory architecture \cite{Kelly}, which involves a memory unit with input, output, and feedback gates and is intended to overcome the problem of vanishing gradients over long sequences of inputs. Although the recurrent neural network produced reasonable results with recall and precision scores of 0.85\% and 0.36\% and thus a F-score of 51\%, \cite{Kelly} experimented with several types of neural networks, and this one did not produce the best results. In particular it performed poorly on appliances with more than the two, on/off states. The neural network we used, which falls into a category called denoising autoencoders, was based on another of the nets \cite{Kelly} tested which outperformed the recurrent neural network. This paper, which discusses generating aggregate data by randomly recombining sections of the power consumption of single devices, is also the source of our idea to experiment with using synthetic power consumption data to deal with the problem that deep neural networks need very large amounts of data to train on \cite{Kelly}.


\section{Our Stuff}

%TODO: This one could be useful
%Known as nonintrusive load monitoring (NILM) various researchers have investigated this problem.
%Weiss (Source3?) presume the power consumption as a sequence of piecewise constant consumption levels whose differences describe the typical consumption pattern of a distinct device.
%Since they get remarkable F-scores of 80\% and higher for some devices we also had a look for signal where this assumption holds.

Unlike many of the other methods, we are assuming that we do not have the disaggregated power signature for each device during the learning stage.
Instead, we assume we have accurate information about when each device is active, due to the trend of the "Internet of Things", where many devices are connected to the internet, and could thus provide information about when they are active.
%TODO: Get paper for this?


\subsection{Dataset}
As a basis to evaluate our approach we use the Reference Energy Disaggregation Data Set (REDD) \cite{Redd}, a collection of energy consumption 
from six houses where the mains, single devices and circuits were measured separately over two weeks. Even though the data set contains high-frequent 
measurings we use the ones with frequencies between $1$ and $3 Hz$, to stay comparable to former works with similar frequencies. Since not all 
device exist in every house we focused on the most common ones: dishwasher, washer-dryer-combinations (both in all houses), refridgerator (in 5 
out of 6 houses) as well as microwave and stove (in all but two houses). Since the sum of all single devices and circuits does not sum up to the 
measured overall consumption, because small devices like consumer electronics were not traced, we compare two different approaches one with noise 
and one without. For the unnoised method we sum up only the consumption of the focused devices and take their sum as the aggregated energy consumption. 
We check these results against the ones where we subtract the devices which are not of interest for us from the measured overall consumption, which 
gives us a bigger than natural noise.\\
Our goal is to work only with the information if a device is inactive or active, whereby active means that it is actually on and not only in a
standby mode. To generate the  on/off-indicators we check the dataset against a threshold $\delta$, assigning the device an indicator of $1$ if its 
consumption in the relevent time step exceeds the threshhold and considering the device as inactive otherwise, assigning $0$. Using the threshold 
eliminates the uninteresting phases of permant standby uses, as they are common especially in refridgerators.

\subsubsection{Denoising Autoencoders}

The neural network we used, as mentioned above, belongs to a type called denoising autoencoders and is based on the one from \cite{Kelly}. An autoencoder is a type of neural network with input and output layers the same size and a smaller hidden layer between them where the input and the target are the same. As a result the output of the hidden layer is effectively a compressed encoding of the original data. A denoising autoencoder is one where the input is a corrupted version of the signal, and the output is checked against the uncorrupted version. They are typically used to remove grain and noise from photos and sound recordings. 

Denoising autoencoders can be applied to energy disaggregation by using a separate neural network for every appliance and using the power consumption over an extended window of time as both the input and the output. The input or corrupted signal is a vector of size T giving the aggregated power consumption over a time window of length T, and the target or uncorrupted signal is another vector giving the power consumption of one appliance over the same window, so the other appliances in the aggregated power usage are treated as noise \cite{Kelly}. Using the power over a time window as input is why it is able to recognise patterns in power consumption over time without being a recurrent neural net.

Having discussed denoising autoencoders in general, we move on to the details of the neural networks we used. Each appliance had its own network as mentioned above, and each of them had six layers. The size of the input window was customized to how long each appliance was turned on, on average, so the input layer varied in size between the networks. After the input window was a convolutional layer with eight filters of size four. The third and fifth layers were both dense layers the same size as the output of the first convolutional layer with a smaller dense layer of 128 nodes between them. These three layers are what make up the actual denoising autoencoder. The final layer was a second convolutional one with one filter of size four \cite{Kelly}. The final layer treats its input as eight dimensional rather than one, and so reverses the increase in the size of the layers caused by the eight filters of the first convolutional layer, and compresses the output back down to the correct size to be compared to the target.

In addition, we experimented with using a smaller neural network containing just the input and three denoising autoencoder layers and not the convolutional layers. The idea was that by reducing the number of layers and weights to train we would increase our chances of getting good results with a limited amount of data to train on.

We also standardized the input before running the neural network. Every input window had its mean subtracted. This does lose some information, but experiments, both our own and \cite{Kelly}'s, suggest that neural networks generalize better when each sequence is centered separately and that the gains from this outweigh loses from throwing away the information about the average value. Also every sample was divided by the standard deviation of a random sample of the input, and the target output was divided by the maximum power demand of the device to put it in the range of 0 to 1 \cite{Kelly}. One potential weakness of the architecture we used, which separates the appliances into different neural networks, is that it loses information about the relationship between appliances such as that, taking small unmonitored appliances into account, the individual power consumption of the appliances must sum to less than or equal to the aggregate power consumption. However, using a single large network that output the dissagregated power consumption of all the appliances might be less useful than it seems at first, since standardizing the input by subtracting the mean would stymie learning based on the above pattern, for example, but as previously mentioned neural networks do not tend to generalize as well when the input is not standardized.

For resutls, the paper comparing neural networks shows the denoising autoencoder as having a recall score of 94\%, a precision score of 56\%, and thus an F-score of 70\% \cite{Kelly}. Before we ran our experiment based on just the on/off binary information, we ran our denoising autoencoder with the actual disaggregated power consumption as the target output on the REDD dataset attempting to get numbers close to these ones to test that our neural network was working correctly.

\section{Preprocessing}

Robust evaluation metrics are essential to applying supervised learning techniques. Unfortunately, obtaining reasonable metrics is near impossible without actual power outputs of individual devices. Nonetheless, we are still interested in applying supervised approaches, which have a strong history of success in the energy disaggregation literature. Our solution separately estimates the individual power outputs on each device on the training data, as a preprocessing step to train a more powerful prediction algorithm. We emphasize that as a general prediction method, the preprocessing algorithms we describe are not viable, since after the training phase we have no access to device on/off indicators, which are key in obtaining power output.

Inferring general power outputs is an underdetermined problem. Good results can therefore only be obtained by making strict assumptions about the statistical model producing the data. Here, we apply two separate models: The simplest assumes that good estimates are obtained from a constant power estimate, the second that each device is represented by a restricted family of markov processes.

In the sequel, the following notation will be convinient. We shall let $N$ denote the number of devices we are observing, and $T$ the number of time epochs. The random variable $X_i^t$ models the output of the device $i$ at the time $t$, and $Y^t = \sum X_i^t$ denotes the total power output as $t$ ranges over time. We observe both the indicators $I_i^t = \mathbf{I}(X_i^t > 0)$ and $Y^t$ over the range of $i$ and $t$, and must predict the $X_i^t$ to the best of our ability.

\subsection{A Constant Power Assumption}

In our first model, we assume that the output of devices are mutually independant, and that the outputs of a specific device are independant and identically distributed with respect to time, given that the device is switched on. The mathematics tells us that there are numbers $P_1, \dots, P_n \in \mathbf{R}^+$ for which $X_i^t \sim P_i + \varepsilon_i$, where $\mathbf{E}(\varepsilon_i) = 0$. Given that the variances $\mathbf{V}(\varepsilon_i)$ are small, it can be inferred that the variables do not deviate far from their average with respect to the $L_2$ norm, and therefore a constant power approximation for each device is accurate. Our problem reduces to finding the values $P_i$. After the $P_i$ are predicted, output estimations are calculated via the equation
%
\[ \hat{X_i^t} = I_i^t P_i \]
%
Finding $P_i$ is very feasable, once an optimization metric is chosen.

The simplest way to choose the $P_i$ is to minimize the $L_2$ error of our estimated total
%
\[ \hat{Y}^t = \sum_{i = 1}^n \hat{X_i^t} = \sum_{i = 1}^n I_i^t P_i \]
%
with respect to the known total $Y^t$. This can be easily found by the optimization
%
\[ \min_{P_1, \dots, P_n \in \mathbf{R}^+} \sum_{t = 1}^T \left( Y^t - \sum_{i = 1}^n I_i^t P_i \right)^2 \]
%
In our implementation, we use Scipy's {\it optimize()} method to determine the $P_i$, which uses sequential least squares to calculate the optimum.

\subsection{Confidence Intervals}

Optimizing the $L_2$ eror of the problem treats the problem as a data-fitting task, and ignores the stochastic nature of the problem. We may obtain better estimates via a method explicitly considering the random nature of the task. Note that, with the i.i.d. assumptions on the data, we can view the determination of the $P_i$ as a problem in estimation statistics, analogous to a statistical study on a well-chosen sample. Our exterior knowledge of the problem (the indicator functions and total power output), we are able to infer a number of samples of the $P_i$ from the data given, which we may use to construct an estimator. A statistical study is evalated by confidence in the estimators attained. We propose that choosing the $P_i$ to minimize these confidence intervals results in a good estimate of the $P_i$, since we maximize the accuracy by which we obtain the $P_i$.

How do we obtain direct samples of a certain $P_i$ from the $Y_t$ and $I_i^t$ that we are given? One method is to take $Y^t$ solely from times where $I_i^t = 1$, and $I_j^t = 0$ for $j \neq i$. It follows in these rare cases that $Y^t = X_i^t$, and we may obtain a series of estimates for the $i$'th device. To obtain more estimates, it may be of interest to instead consider circumstances $t$ where $I_i^{t-1} \neq I_i^t$, but $I_j^{t-1} = I_j^t$ for $j \neq i$. We infer that $|Y_t - Y_{t-1}| \sim X_i^t + 2 \sum_{I_j^t = 1, j \neq i} \varepsilon_j$. Nonetheless, the equation above shows that our estimates have more error terms, so we likely need many more samples to obtain the same results.

We cannot do much more to obtain further estimates. Under our assumptions, we are effectively observing a discrete embedding in a continuous time markov process. In such a process, given our discrete embedding is suitable fine, two state changes in a single time epoch are very rare. It follows that this estimate is pretty much the best we can do, since we are obtaining estimates for almost every single time the device changes state, since multiple devices running at the same time obscure the sampling process.

Now suppose the estimates $\hat{P_i}$ have been derived from the data given. If we trust at least one of our estimates, we may `erase it' from the rest of the data, replacing $Y^t$ with $Y^t - I_i^t \hat{P_i}$. We may then treat the sample as if the $i$'th device was never on. By recursively following these steps, removing $\hat{P_{i_1}}$, then $\hat{P_{i_2}}$, up to $\hat{P_{i_N}}$, we obtain final estimates of each sample. We hope to remove the estimates in such an order such that the confidence intervals are optimized. Global optima for this step are combinatorially difficult to find. Instead, we just use a greedy heuristic -- remove the estimate with the smallest variance, which assuming that the errors are normally distributed, is proportional to the confidence interval. Better results may be obtained if one accounts for the number of additional samples one may obtain if the device is not removed at a certain time.

\subsection{Estimating Difference Markov Processes}

The constant time assumption is a simple method for estimating power outputs, but it is somewhat simple, resulting in poor performance on actual applications. An alternate model of the data-generating process assumes the underlying appliance power generators are mutually independant markov models. For introductory facts about Markov models, refer to a basic book in Markov models (e.g. Lawler).

As an extension of the previous model, the power outputs of devices are constant when the underlying chain remains in a single state. This should suffice for most practical applications, since most appliances change their power load only when running in a different `mode' (an oven cooking at different temperatures, a computer under different stress levels, etc.).

Mathematically speaking, the outputs $X_i^t$ are drawn from some hidden markov model with states $S^i_0, S^i_1, \dots, S^i_{K_i}$, where $S_0$ is the `off' state ($X_i^t = 0$) and that, given that the markov model is in a state $S^i_k$ at some time $t$, then $X_i^t \sim \mu_i^k + \varepsilon_i^k$, where $\mathbf{E}(\varepsilon_i) = 0$, and $\mu_i^k \in \mathbf{R}^+$ are fixed. Once we have estimated such a model, we may estimate the $X_i^t$ by a best fit method -- calculating the state transition that results in the best fit. We don't ever need to calculate transition probabilities, since our knowledge of the indicator functions effectively removes most of the randomness from the calculation.

Hidden markov chains are still difficult to estimate, so restriction of the markov model's structure is necessary. In words, we restrict the model such that it is unable to transition from any on state to any on state directly -- it must pass through the off state in order to transition to these states. A general diagram for such a markov chain is displayed below. It is hard enough to estimate the means, so we assume that the states of the markov diagram have been given by divine insight -- this is a classic problem; too many states will overfit the data, too few will underfit.

To further reduce the dimensionality of the we, problem follow Kolter's approach to the Markov model problem by considering difference Markov models\footnote{described in [1], in particular during his discussion of additive and factorial markov models}. Rather than working with the data $Y^t$, we choose only to use values $\Delta Y^t := Y^t - Y^{t-1}$ at timepoints $t$ where the $i$'th device switches on ($\mathbf{I}(X_i^{t-1} > 0) = 0$ and $\mathbf{I}(X_i^t > 0) = 1$). Hopefully, this difference describes the average power over the entire interval where the device is switched on. Even if it doesn't, we should have enough data to make these approximations accurate enough on average. At these time points, it is very likely that our device will be the only device to change state, as discussed before, since a continuous time markov chain changes two states very rarely in a short time period. We then attempt to optimize our choice of $\mu_i$ redefining $X_i^{t + k} = \Delta Y^t$, where $X_i^{t + l} > 0$ for $l \in \{0, 1, \dots, k\}$.

Now we shall describe the optimization for a specific device $i$. Suppose that, the device enters a series of intervals of lengths $l_1, \dots, l_M$, taking difference values $\Delta Y^{t_1}, \dots, \Delta Y^{t_M}$ in each interval. We proceed to determine the values $\mu_1, \dots, \mu_K$ by minimizing the $L_2$ best fit over the data.
%
\begin{equation} \min_{\mu_1, \dots, \mu_K} \sum_{i = 1}^M l_i \min_{k \in \{ 1, \dots, K \}}(\Delta Y^{t_i} - \mu_k)^2 \end{equation}
%
There is a geometric interpretations of this minimization. Viewing the $\Delta Y^{t_i}$ as points, each with a `weight' $l_i$, we are attempting to choose the best centers of mass $\mu_1, \dots \mu_K$ which distribute themselves evenly between the points $\Delta Y^{t_i}$.

If we only have one mean to distribute over all $Y^{t_k}$, then the best choice is the weighted mean
%
\[ \mu = \frac{\sum_{k = 1}^m l_k Y^{t_k}}{\sum_{k = 1}^m l_k} \]
%
obtained by differentiating (1) with respect to $\mu$, and simplifying the formula. Now suppose $\mu_1 < \mu_2 < \dots < \mu_K$ is the optimal solution to our problem. If we remove $\mu_K$, then $\mu_1 < \dots < \mu_{K-1}$ is the optimal solution to the subproblem of distributing $K-1$ means among the subset of points who's closest mean is not $\mu_K$ (for otherwise we can move these means to improve our current solution). The optimal choice of $\mu_K$ then becomes the weighted mean of points who are close to $\mu_K$ as possible. Dynamic programming arises from optimal substructure, and we obtain the simple recurrence: If we let $L(m,k)$ be the optimum cost of putting $k$ of the $\mu_i$ in the range $\{ t_1, \dots, t_m \}$, then we may choose an interval $\{ t_p, \dots, t_m \}$ for which $\mu_k$ will be the closest estimate, and then we optimize over $\{ t_1, \dots, t_p \}$ with one less estimate. Our reccurence is
%
\begin{align*}
    L(m,k) = \min_{k \leq p < m} \bigg\{ L(p,k-1) + \frac{\sum_{j = p+1}^m l_j Y^{t_j}}{\sum_{j = p+1}^m l_j} \bigg\}
\end{align*}
%
\[ L(m,1) = \frac{\sum_{j = 1}^m l_j Y^{t_j}}{\sum_{j = 1}^m l_j} \]
%
If we calculate the weighted mean over time, then we may calculate the recurrence in $O(M^3)$ time. In one swoop, we may recursively calculate the means in quadratic time, reducing the asymptotics to $O(M^2)$. By keeping track of the location of the last means recursively, we can build up the optimal choice of means, and reconstruct our data for use in our neural network.

% We thank Zachary Friggstadt for helping optimize the l_1 norm version of the problem.

\subsection{Evaluation}
To compare our methods with each other and with existing approaches, we focus on two questions.\\
1. How well did we identify what devices where active in each time step?\\
2. How well did we identify the single devices‘ consumption?\\
To address the first question we use the F1-Score, ensuring our results to be comparable to the works in the section \textit{Literature}. The 
advantages of the F1-Score to combine recall and precision avoids contortions, which would arise by considering only one of them. Assume we 
identify the refridgerator being active in all time steps we get a optimal recall value, but a low precision, whereas we get a optimal precision 
by identifying the refridgerator never as active.
\[ \textrm{Precision} = \frac{\textrm{Number of true positive elements}}{\textrm{Number of elements identified as positives}}  \]
\[ \textrm{Recall} = \frac{\textrm{Number of true positives}}{\textrm{Number of elements that are indeed positive}}  \]
\[ \textrm{F1-Score} = \frac{2 \cdot \textrm{Precision} \cdot \textrm{Recall}}{\textrm{Precision} + \textrm{Recall}}\]
For the second question we are interested in the error per timestep and to generate acuuracy-like value. Therefore we
compare the disaggregated energy consumptions per device with the actual device's consumption we have from the REDD
dataset. Following \cite{Redd} we can compute the accuracy depending on the summed absolute deviation in relation to 
the overall consumption:
\[\textrm{Accuracy}_{abs} = 1- \frac{\sum^{T}_{t=1}\sum^{N}_{n=1}|\hat{y}^{(n)}_t-y^{(n)}_t|}{2 \sum^{T}_{t=1}Y_t} .  \]
The error per timestep can be similarly described as the absolute squared error:
\[\textrm{ASE} = \frac{\sum^{T}_{t=1}\sum^{N}_{n=1}|\hat{y}^{(n)}_t-y^{(n)}_t|}{T \cdot n} .  \]
While the absolute error weights all differences regardless of their size the same, we also want information about the accuracy when 
weighting bigger deviations higher than smaller ones. We use the root squared error instead of the squared error 
to stay within the same unit. Therewith we calculate the root mean squared error as the error per timestep and similar a respective 
accuracy as the ratio with summed up overall consumption.
\[\textrm{RMSE} = \sqrt{\frac{\sum^{T}_{t=1}\sum^{N}_{n=1}(\hat{y}^{(n)}_t-y^{(n)}_t)^2}{T \cdot n}} .  \]
\[\textrm{Accuracy}_{rse} = 1- \frac{\sqrt{\sum^{T}_{t=1}\sum^{N}_{n=1}(\hat{y}^{(n)}_t-y^{(n)}_t)^2}}{2 \sum^{T}_{t=1}Y_t} .  \]




%TODO: Whatever evaluation function to see how well the neural network does after training.
%May even want to use two or more, to see if they work better in different circumstances

%Then, we will compare the results for the different trained denoising autoencoder neural nets, based on the data that we preprocessed.

%Will train and evaluate on the devices %TODO: write out devices


%TODO: Example?



%TODO: Example?

\subsection{Implementation}
Our NILM and pre-processing implementations were written in Python, and are publicly available in our \href{https://github.com/CMPUT-466-551-ML-Project/NILM-Project}{NILM-Project} repository.

After choosing which devices from each home we wanted to train our networks against, we removed the contribution of all other devices present in the home from each home's aggregated power time-series.
We chose this approach, instead of generating new aggregated data by taking the sum of the power signal of the chosen devices from each home, in order to preserve the noise present in the aggregated power time-series.
This noise is present even when no recorded device in the home is active, and therefore needed to be preserved so that our networks could account for it during training.

The original data we used had some periods of missing data, and not all devices were sampled at the same frequency.
To overcome this, we padded our time-series data to be fully aligned across all devices and the aggregate recording.
Any missing sample period of less than 600 seconds was padded with the most-recently recorded power value.
Any missing sample period of more than 600 seconds was thrown out.
We used this padded data for training and evaluation.

In order to recover the binary on-off indicators for each device from the power signal, we use a simple thesholding algorithm.
If the power signal is over the threshold, we say that the device is on, and if the power signal is below the threshold, we say that the device is off.
In our implementation, we used a base threshold of 25W across all devices, to account for noise present in the signal.

Our pre-processing algorithms use these recovered binary on-off indicators, along with the padded aggregated data of each home, in order to generate an approximation of the device power usage for use when training our networks.

We implemented our neural networks using the Keras library \cite{Keras}.
Keras is built on top of the Theano library \cite{Theano}\cite{Theano2}.
Our network weights were initialized randomly from a uniform distribution.
All experiments described in this paper were trained end-to-end from the random initialization.
The input size of each network was chosen as the average activation length of the device the network was trained against.
The input size was bounded to a maximum 1500 seconds, due to memory constraints on the machines the networks were trained on.

\section{Discussion}

\subsection{Future work and Extension}

Extension to Baranski's Algorithm?.

HMM depending on how well that goes

Another possible extension to this project would be to add more information to the input of the neural network, such as the time of day and day of the week of the input window since certain appliances are more likely to be activated at certain times. Another option would be to find a way to include the information of what the mean of the input window was while still standardizing each input window by subtracting its mean\cite{Kelly}, perhaps by standardizing the power consumption used as the input and then adding the mean as a single number at the end of the input. However, it is not easy to see where the best place to insert this information into the denoising autoencoder architecture would be. Some experimentation would likely be necessary to find an architecture that made effective use of the new information.

% Generate the bibliography.

\bibliography{biblio}
\bibliographystyle{aaai}

\end{document}
